#!/usr/bin/env python3
from urllib.request import HTTPPasswordMgrWithPriorAuth
from urllib.request import HTTPBasicAuthHandler
from urllib.request import HTTPCookieProcessor
from urllib.request import build_opener
from http.cookiejar import CookieJar
from urllib.error import HTTPError
from urllib.parse import urlencode
from urllib.request import Request
from dataclasses import dataclass
from xml.etree import ElementTree
from os.path import expanduser
from datetime import datetime
from base64 import b64encode
from getpass import getpass
import subprocess
import webbrowser
import itertools
import json
import time
import sys

NEXTCLOUD_URL = "http://192.168.1.161"
USER_AGENT = b"overcast-to-gpodder 0.1 (milkey-mouse/overcast-to-gpodder)"

# this cache is probably most useful during development,
# or if you run this script regularly (if so... why?)
DURATION_CACHE_LOCATION = expanduser("~/.cache/overcast-to-gpodder.json")
DURATION_CACHE = {}

try:
    with open(DURATION_CACHE_LOCATION) as f:
        DURATION_CACHE = json.load(f)
except FileNotFoundError:
    pass


class FeedIndex:
    ITUNES_DTD = "{http://www.itunes.com/dtds/podcast-1.0.dtd}"
    ITUNES_DTD_HTTPS = ITUNES_DTD.replace("http", "https")

    @dataclass
    class FeedItem:
        itunes_title: str
        title: str
        urls: set[str]
        guid: str
        duration: int

    def __init__(self, f):
        self.titles = {}
        self.itunes_titles = {}
        self.urls = {}

        def upsert(name, into, key, val):
            if key is not None:
                if key in into:
                    print(
                        f"warning: {name} '{key}' referenced in multiple entries, using last",
                        file=sys.stderr,
                    )
                into[key] = val

        for item in self.parse_feed(f):
            entry = (item.guid, item.duration)
            upsert("title", self.titles, item.title, entry)
            upsert("iTunes title", self.itunes_titles, item.itunes_title, entry)
            for url in item.urls:
                upsert("URL", self.urls, url, entry)

    def find(self, title=None, itunes_title=None, url=None):
        title = title or itunes_title
        itunes_title = itunes_title or title

        return (
            self.titles.get(title)
            or self.itunes_titles.get(itunes_title)
            or self.urls.get(url)
        )

    @classmethod
    def parse_feed(cls, f):
        in_channel = False
        item = None
        depth = 0

        for event, e in ElementTree.iterparse(f, events=("start", "end")):
            if event == "start":
                depth += 1
            elif event == "end":
                depth -= 1

            if depth == 2 and e.tag == "channel":
                in_channel = True
            elif depth == 1 and in_channel:
                in_channel = False
                continue
            elif not in_channel:
                continue

            if depth == 3 and e.tag == "item":
                item = cls.FeedItem(None, None, set(), None, None)
                duration = guid = itunes_title = title = None
                urls = set()
            elif depth == 2 and item:
                yield item
                item = None
                continue
            elif not item:
                continue

            if depth == 4:
                tag = e.tag.replace(cls.ITUNES_DTD, "itunes:")
                tag = tag.replace(cls.ITUNES_DTD_HTTPS, "itunes:")

                if tag == "itunes:title":
                    item.itunes_title = "".join(e.itertext())
                elif tag == "title":
                    item.title = "".join(e.itertext())
                elif tag == "enclosure":
                    item.urls.add(e.get("url"))
                elif tag == "guid":
                    # TODO: does isPermalink="false" imply we shouldn't use it?
                    item.guid = "".join(e.itertext())
                elif tag == "itunes:duration":
                    try:
                        item.duration = int("".join(e.itertext()))
                    except ValueError:
                        # invalid or empty (but existing!)
                        # duration tags are sadly common
                        item.duration = None


class Overcast:
    def __init__(self, email, password):
        self.session = build_opener(HTTPCookieProcessor(CookieJar()))
        self.session.addheaders = [(b"User-Agent", USER_AGENT)]
        return  # TODO: debug mode
        with self.session.open(
            Request(
                "https://overcast.fm/login",
                data=urlencode(
                    {
                        "email": email,
                        "password": password,
                    }
                ).encode("utf-8"),
            )
        ) as r:
            # ignore the response; only did this request for the session cookie
            while r.read(8192):
                pass

    def listened(self):
        #with self.session.open("https://overcast.fm/account/export_opml/extended") as r:
        with open("/home/milkey/overcast.opml") as r:
            in_feeds = False
            feed = feed_index = None
            for event, e in ElementTree.iterparse(r, events=("start", "end")):
                if e.tag != "outline":
                    continue
                elif e.get("text") == "feeds":
                    if event == "start":
                        in_feeds = True
                    elif event == "end":
                        in_feeds = False
                elif not in_feeds:
                    continue
                elif e.get("type") == "rss":
                    if event == "start":
                        feed = e.get("xmlUrl")
                        print(f"opening feed {feed}")
                        try:
                            with self.session.open(feed) as r:
                                feed_index = FeedIndex(r)
                        except HTTPError as e:
                            print(
                                f"couldn't open RSS feed {feed}: {e.code} {e.reason}",
                                file=sys.stderr,
                            )
                    elif event == "end":
                        feed = feed_index = None
                elif e.get("type") == "podcast-episode" and e.get("played") == "1":
                    if event == "end":
                        assert feed is not None
                        # TODO: warn on no GUID?
                        title = e.get("title")
                        url = e.get("enclosureUrl")
                        (guid, duration) = self.get_guid_and_duration(
                            feed_index, title, url
                        )
                        yield (feed, url, guid, duration)

    @classmethod
    def get_guid_and_duration(cls, feed_index, title, url):
        guid = None
        duration = None
        try:
            (guid, duration) = feed_index.find(title=title, url=url)
        except Exception:
            pass

        duration = duration or DURATION_CACHE.get(url)

        if not duration:
            print(
                f"no duration in feed for '{title}'; reading the audio file ourselves"
            )
            try:
                p = subprocess.run(
                    [
                        "ffprobe",
                        "-show_entries",
                        "format=duration",
                        "-v",
                        "quiet",
                        "-of",
                        "csv=p=0",
                        url,
                    ],
                    stdout=subprocess.PIPE,
                    stderr=sys.stderr,
                    check=True,
                )
                duration = int(p.stdout.split(b".")[0])
                DURATION_CACHE[url] = duration
            except subprocess.CalledProcessError:
                print(
                    f"ffprobe didn't exit successfully for '{url}'; we'll lie about the length of '{title}'",
                    file=sys.stderr,
                )
            except FileNotFoundError:
                print(
                    f"could not run ffprobe; we'll just lie about the length of '{title}'",
                    file=sys.stderr,
                )

        if not duration:
            # fall back to 10 minutes if we can't find the real duration. we
            # only use this as a last resort, as some apps won't consider 10
            # minutes into a "10-minute podcast" that's actually >10 minutes
            # as having completed that episode. (gPodder has no "action" to
            # mark an episode as completed, so apps rely upon the playback
            # position being at the end of the file instead.) but if we can't
            # find the real duration ourselves, we just lie for the sake of
            # marking the episode as played.
            duration = 1200

        return (guid, duration)


# https://stackoverflow.com/q/21663800#46841935
class SerializableGenerator(list):
    def __init__(self, iterable):
        tmp_body = iter(iterable)
        try:
            self._head = iter([next(tmp_body)])
            self.append(tmp_body)
        except StopIteration:
            self._head = []

    def __iter__(self):
        return itertools.chain(self._head, *self[:1])


def json_chunked(iter):
    for chunk in json.JSONEncoder().iterencode(iter):
        yield chunk.encode("utf-8")


class Nextcloud:
    def __init__(self, url, user=None, password=None):
        self.url = url
        self.session = build_opener(HTTPCookieProcessor(CookieJar()))
        self.session.addheaders = [(b"User-Agent", USER_AGENT)]

        if user and password:
            self.user = user
            self.password = password
        else:
            with self.session.open(
                Request(self.url + "/index.php/login/v2", method="POST")
            ) as r:
                challenge = json.load(r)

            webbrowser.open(challenge["login"])

            data = urlencode({"token": challenge["poll"]["token"]}).encode("utf-8")
            poll_request = Request(challenge["poll"]["endpoint"], data=data)

            # "The token will be valid for 20 minutes."
            challenge_expiry = time.monotonic() + (20 * 60)
            while time.monotonic() < challenge_expiry:
                try:
                    with self.session.open(poll_request) as r:
                        response = json.load(r)
                        self.user = response["loginName"]
                        self.password = response["appPassword"]
                        break
                except HTTPError as e:
                    if e.code == 404:
                        time.sleep(1)
                    else:
                        raise

        auth = b64encode(f"{self.user}:{self.password}".encode("utf-8"))
        self.session.addheaders.append((b"Authorization", b"Basic " + auth))

    def subscriptions(self):
        with self.session.open(
            self.url + "/index.php/apps/gpoddersync/subscriptions"
        ) as r:
            resp = json.load(r)
            # I *think* this is the intended semantics?
            yield from set(resp["add"]) - set(resp["remove"])

    def update_subscriptions(self, add=[], remove=[]):
        with self.session.open(
            Request(
                self.url + "/index.php/apps/gpoddersync/subscription_change/create",
                headers={b"Content-Type": b"application/json"},
                data=json_chunked(
                    {
                        "add": SerializableGenerator(add),
                        "remove": SerializableGenerator(remove),
                    }
                ),
            )
        ) as r:
            while r.read(8192):
                pass

    def subscribe(self, feeds):
        self.update_subscriptions(add=feeds)

    def unsubscribe(self, feeds):
        self.update_subscriptions(remove=feeds)

    def mark_listened(self, episodes):
        timestamp = datetime.now().isoformat(timespec="seconds")

        last_action = "play"
        while last_action:
            last_action = None

            ten_episodes = itertools.islice(episodes, 10)
            with self.session.open(
                Request(
                    self.url + "/index.php/apps/gpoddersync/episode_action/create",
                    headers={b"Content-Type": b"application/json"},
                    data=json_chunked(
                        SerializableGenerator(
                            {
                                "podcast": feed,
                                "episode": url,
                                "guid": guid,
                                "action": (last_action := "play"),
                                "timestamp": timestamp,
                                "position": duration,
                                "started": duration,
                                "total": duration,
                            }
                            for (feed, url, guid, duration) in ten_episodes
                        )
                    ),
                )
            ) as r:
                while r.read(8192):
                    pass


overcast = Overcast(
    email=input("Overcast email: "),
    password=getpass("Overcast password: "),
)

nextcloud = Nextcloud(NEXTCLOUD_URL)

# --clobber-existing option doesn't work right with AntennaPod;
# it seems it won't associate listen events with new subscriptions?
# I think it may have something to do with the timestamps
#subscriptions = set(nextcloud.subscriptions())
#if "--clobber-existing" in sys.argv[1:] and subscriptions:
#    nextcloud.unsubscribe(subscriptions)
#    subscriptions = set()

for feed, listened in itertools.groupby(overcast.listened(), key=lambda x: x[0]):
    if feed not in subscriptions:
        nextcloud.subscribe((feed,))
        subscriptions.add(feed)
    nextcloud.mark_listened(listened)

if "--cache" in sys.argv[1:]:
    try:
        with open(DURATION_CACHE_LOCATION, "w") as f:
            json.dump(DURATION_CACHE, f)
    except FileNotFoundError:
        pass

# pprint.pprint(set(nextcloud_listened(NEXTCLOUD_URL, auth)) - set(overcast_listened()))
# pprint.pprint(set(overcast_listened()) - set(nextcloud_listened(NEXTCLOUD_URL, auth)))

# def nextcloud_listened(url, auth):
#    auth = b64encode(":".join(auth).encode("utf-8"))
#    with urlopen(
#        Request(
#            url + "/index.php/apps/gpoddersync/episode_action",
#            headers={
#                b"Authorization": b"Basic " + auth,
#                b"User-Agent": USER_AGENT,
#            },
#        )
#    ) as r:
#        response = json.load(r)
#        for action in response["actions"]:
#            yield action["episode"]
